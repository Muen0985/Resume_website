<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning Projects Showcase</title>
    <style>
        /* General Styles */
        body {
            font-family: 'Roboto', sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f0f2f5;
            color: #333;
        }

        main {
            max-width: 1200px;
            margin: 20px auto;
            padding: 0 20px;
        }

        .project {
            background: #fff;
            margin-bottom: 20px;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s, box-shadow 0.3s;
            position: relative;
        }
        
        .project h2 {
            margin-top: 0;
            font-size: 1.8rem;
            color: #007bff;
            display: inline-block;
        }

        .project nav {
            position: absolute;
            top: 20px;
            right: 20px;
        }

        .project nav a {
            color: #fff;
            text-decoration: none;
            margin-left: 10px;
            padding: 10px 20px;
            background: #85a4c5;
            border-radius: 5px;
            transition: background 0.3s;
        }

        .project nav a:hover {
            background: #003f7f;
        }

        .project img {
            width: 100%;
            height: auto;
            border-radius: 10px;
            margin: 20px 0;
            margin-left: 20px;
            max-width: 500px;
            border: 1px solid rgb(176, 176, 176);
        }

        .project figcaption {
            text-align: left;
            font-style: italic;
            color: #555;
            margin-bottom: 20px;
        }

        .project h3 {
            margin-top: 0;
            font-size: 1.8rem;
            color: #6287ae;
            margin-bottom: 10px;
        }

        /* Responsive Styles */
        @media (max-width: 768px) {
            .project {
                padding: 15px;
            }

            .project h2 {
                font-size: 1.5rem;
            }
        }
    </style>
</head>
<body>
    <main>
        <!-- Project 1 -->
        <section class="project">
            <nav>
                <a href="index.html">回到首頁</a>
                <a href="pp5.html">回到專案項目</a>
            </nav>
            <h2>Project 1</h2><br>
    
            <p><strong>Background:</strong> 使用機器學習套件來將影片音訊轉成文字，再藉由文章摘要擷取出重點部分。</p>
            <p><strong>Data Source:</p>
            <img src="https://i.ytimg.com/vi/yJ-gxcRVu1c/maxresdefault.jpg" alt="YouTube Preview" style="max-width: 200px;">
            <img src="https://i.ytimg.com/vi/K1saMpQCBmE/maxresdefault.jpg" alt="YouTube Preview" style="max-width: 200px;">
            <figcaption>挑選了一段長度3:20的影片及30秒的shorts,
                作為音訊資料
            </figcaption>
            <br><br>
            <h3>Model Selection</h3>
            
            <p><strong>Model : </strong>音訊轉文字 -  OpenAi whisper 、 speech_recognition &nbsp;&nbsp; 文章摘要擷取 -  bert-extractive-summarizer</p>
            <br><br>
            <h3>Results</h3>
            <p><b>語音辨識 :</b></p>
            <img src="src_image/ML_Sklearn/sound_result.png" alt="YouTube Preview" style="max-width: 400px;">
            <img src="src_image/ML_Sklearn/sound_result2.png" alt="YouTube Preview" style="max-width: 500px;">
            <figcaption> podcast shorts (左): 可以看出Whisper產出的文字比speech_recognition更無缺漏且準確</figcaption>
            <figcaption>espn video(右): Whisper產出相較speech_recognition大約多了50多個字</figcaption>
            <hr><br>
            <p><b>文章摘要擷取 :</b></p>
            <img src="src_image/ML_Sklearn/summary_text.png" alt="YouTube Preview" style="max-width: 450px;">
            <figcaption>皆使用 bert-extractive-summarizer，若參數調整好效果還不錯，想知道的訊息大致都有保留住</figcaption>
            <br><br>
            <h3>Code Demo</h3>
            <img src="src_image/ML_Sklearn/sr_code.png" alt="YouTube Preview" style="max-width: 450px;">
            <img src="src_image/ML_Sklearn/wh_code1.png" alt="YouTube Preview" style="max-width: 450px;">
            <figcaption>第一張圖片是使用speech_recognition的程式 &nbsp;/ &nbsp; 第二張圖片是使用OpenAI Whisper的程式 (model size: small)</figcaption>
            <img src="src_image/ML_Sklearn/wh_code2.png" alt="YouTube Preview" style="max-width: 450px;">
            <figcaption>使用bert-extractive-summarizer的程式碼，有根據不同的文章調整參數。例如，shorts本身是影片的精華，因此參數ratio設定擷取約60%的內容</figcaption>

            <br><br>
            <h3>Conclusion 探討模型的技術</h3>
            <h4>OpenAI Whisper:</h4>
            <p>&nbsp;&nbsp; 在實作上whisper的表現較好，Speech_recognition的API我使用的是google web speech
                <br>&nbsp;&nbsp; 但google未公開模型架構，因此研究whisper的模型是如何建構，使錯誤率顯著的降低</p>
            <h4>資料:</h4> 
            <p>&nbsp;&nbsp; Whisper數據集包含68萬小時的標註音訊，使用sequence-to-sequence model來學習語音和其轉錄的文本，<br>&nbsp;&nbsp; 且消除了逆文本正規化步驟，簡化了語音辨識流程<br>
                &nbsp;&nbsp; 將音訊資料分割成每30秒的片段，每個片段都有相應的文本作為訓練標籤，同時使用包含無語音片段的音頻來訓練，以提高區分語音和非語音部分的準確性
                </p>
            <h4>模型 - Transformer encoder / decoder: </h4>
            <p>&nbsp;&nbsp;
                encoder：
                使用小型的stem，包含兩個卷積層，濾波器寬度為3，第二個卷積層步幅為2，並使用GELU激活函數<br>
                &nbsp;&nbsp; decoder：
                解碼器使用學習的位置嵌入和綁定的輸入-輸出標記表示
                編碼器和解碼器具有相同的寬度和Transformer塊數量，確保了模型的對稱性
                </p>
            <h4>訓練: </h4>
            <p>&nbsp;&nbsp; 使用256個片段的批次大小進行訓練，模型經過220次更新，約對數據集進行兩到三次訓練，由於只訓練了幾個epochs，因此過擬合不是問題
                <br>&nbsp;&nbsp; 沒有使用數據增強或正則化方法，而是依賴大型數據集的多樣性促進廣泛性
                </p>
    
    

        </section>
        <!-- Add more sections for additional projects -->
    </main>

</body>
</html>
